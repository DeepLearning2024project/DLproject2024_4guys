\begin{thebibliography}{7}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bai et~al.(2018)Bai, Kolter, and
  Koltun]{DBLP:journals/corr/abs-1803-01271}
Shaojie Bai, J.~Zico Kolter, and Vladlen Koltun.
\newblock An empirical evaluation of generic convolutional and recurrent
  networks for sequence modeling.
\newblock \emph{CoRR}, abs/1803.01271, 2018.

\bibitem[Chung et~al.(2014)Chung, G{\"{u}}l{\c{c}}ehre, Cho, and
  Bengio]{DBLP:journals/corr/ChungGCB14}
Junyoung Chung, {\c{C}}aglar G{\"{u}}l{\c{c}}ehre, KyungHyun Cho, and Yoshua
  Bengio.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock \emph{CoRR}, abs/1412.3555, 2014.

\bibitem[Hochreiter and Schmidhuber(1997)]{10.1162/neco.1997.9.8.1735}
Sepp Hochreiter and JÃ¼rgen Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Wu et~al.(2021)Wu, Xu, Wang, and Long]{NEURIPS2021_bcc0d400}
Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long.
\newblock Autoformer: Decomposition transformers with auto-correlation for
  long-term series forecasting.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  22419--22430. Curran Associates, Inc., 2021.

\bibitem[Wu et~al.(2022)Wu, Hu, Liu, Zhou, Wang, and
  Long]{DBLP:journals/corr/abs-2210-02186}
Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long.
\newblock Timesnet: Temporal 2d-variation modeling for general time series
  analysis.
\newblock \emph{CoRR}, abs/2210.02186, 2022.

\bibitem[Zaremba et~al.(2014)Zaremba, Sutskever, and
  Vinyals]{DBLP:journals/corr/ZarembaSV14}
Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals.
\newblock Recurrent neural network regularization.
\newblock \emph{CoRR}, abs/1409.2329, 2014.

\bibitem[Zeng et~al.(2023)Zeng, Chen, Zhang, and Xu]{Zeng_Chen_Zhang_Xu_2023}
Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu.
\newblock Are transformers effective for time series forecasting?
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  37\penalty0 (9):\penalty0 11121--11128, 2023.

\end{thebibliography}
